<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyspark_ds_toolbox.ml package &mdash; pyspark-ds-toolbox 0.0.2-alpha.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="pyspark_ds_toolbox.causal_inference package" href="pyspark_ds_toolbox.causal_inference.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> pyspark-ds-toolbox
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">pyspark-ds-toolbox</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="pyspark_ds_toolbox.html">pyspark_ds_toolbox package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="pyspark_ds_toolbox.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="pyspark_ds_toolbox.causal_inference.html">pyspark_ds_toolbox.causal_inference package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">pyspark_ds_toolbox.ml package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyspark_ds_toolbox.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark_ds_toolbox.html#module-pyspark_ds_toolbox.wrangling">pyspark_ds_toolbox.wrangling module</a></li>
<li class="toctree-l3"><a class="reference internal" href="pyspark_ds_toolbox.html#module-pyspark_ds_toolbox">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pyspark-ds-toolbox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">pyspark-ds-toolbox</a> &raquo;</li>
          <li><a href="pyspark_ds_toolbox.html">pyspark_ds_toolbox package</a> &raquo;</li>
      <li>pyspark_ds_toolbox.ml package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/pyspark_ds_toolbox.ml.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pyspark-ds-toolbox-ml-package">
<h1>pyspark_ds_toolbox.ml package<a class="headerlink" href="#pyspark-ds-toolbox-ml-package" title="Permalink to this headline"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-pyspark_ds_toolbox.ml.data_prep">
<span id="pyspark-ds-toolbox-ml-data-prep-module"></span><h2>pyspark_ds_toolbox.ml.data_prep module<a class="headerlink" href="#module-pyspark_ds_toolbox.ml.data_prep" title="Permalink to this headline"></a></h2>
<p>Machine Learning (with spark) Data Preparation toolbox.</p>
<p>Module dedicated to functionalities related to data preparation for ML modeling.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.data_prep.binary_classifier_weights">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.data_prep.</span></span><span class="sig-name descname"><span class="pre">binary_classifier_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dfs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></span><a class="headerlink" href="#pyspark_ds_toolbox.ml.data_prep.binary_classifier_weights" title="Permalink to this definition"></a></dt>
<dd><p>Adds a class weight columns to a binary classification response column.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dfs</strong> (<em>pyspark.sql.dataframe.DataFrame</em>) – Training dataset with the col_target column.</p></li>
<li><p><strong>col_target</strong> (<em>str</em>) – Column name of the column that contains the response variable for the model.
It should contain only values of 0 and 1.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If unique values from col_target column are not 0 and 1.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The dfs object with a weight_{col_target} column.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pyspark.sql.dataframe.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.data_prep.get_features_vector">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.data_prep.</span></span><span class="sig-name descname"><span class="pre">get_features_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cat_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></span><a class="headerlink" href="#pyspark_ds_toolbox.ml.data_prep.get_features_vector" title="Permalink to this definition"></a></dt>
<dd><p>Assembles a features vector to be used with ML algorithms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>df</strong> (<em>pyspark.dataframe.DataFrame</em>) – SparkDF with features to be assembled.</p></li>
<li><p><strong>num_features</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of columns names of numeric features.</p></li>
<li><p><strong>cat_features</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List of column names of categorical features (StringIndexer).</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>TypeError</strong> – If num_features AND cat_features are os type None.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The SparkDF passed as df with the features column.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>[pyspark.sql.dataframe.DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.data_prep.get_p1">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.data_prep.</span></span><span class="sig-name descname"><span class="pre">get_p1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark_ds_toolbox.ml.data_prep.get_p1" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-pyspark_ds_toolbox.ml.eval">
<span id="pyspark-ds-toolbox-ml-eval-module"></span><h2>pyspark_ds_toolbox.ml.eval module<a class="headerlink" href="#module-pyspark_ds_toolbox.ml.eval" title="Permalink to this headline"></a></h2>
<p>Machine Learning (with Spark) Evaluation toolbox.</p>
<p>Module dedicated to functionalities related to ML evaluation.</p>
<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.eval.binary_classificator_evaluator">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.eval.</span></span><span class="sig-name descname"><span class="pre">binary_classificator_evaluator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dfs_prediction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_prediction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#pyspark_ds_toolbox.ml.eval.binary_classificator_evaluator" title="Permalink to this definition"></a></dt>
<dd><p>Computes the Matrics of a Binary Classifier from a Prediction Output table from spark.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dfs_prediction</strong> (<em>pyspark.sql.dataframe.DataFrame</em>) – Output Prediction table from spark binarry classifier.</p></li>
<li><p><strong>col_target</strong> (<em>str</em>) – Column name with the target (ground truth)</p></li>
<li><p><strong>print_metrics</strong> (<em>bool</em><em>, </em><em>optional</em>) – Wether to print or not the metrics in the console. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>Exception</strong> – Any error that is encontered</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Dictionery with the following metrics:</dt><dd><ul class="simple">
<li><p>confusion_matrix</p></li>
<li><p>accuracy</p></li>
<li><p>precision</p></li>
<li><p>recall</p></li>
<li><p>f1 score</p></li>
<li><p>aucaoc</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.eval.binary_classifier_decile_analysis">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.eval.</span></span><span class="sig-name descname"><span class="pre">binary_classifier_decile_analysis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dfs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">col_probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></span><a class="headerlink" href="#pyspark_ds_toolbox.ml.eval.binary_classifier_decile_analysis" title="Permalink to this definition"></a></dt>
<dd><p>Computes a Precision, Recall and KS decile analysis from a probability prediction model.
col_target column MUST have values of only 0 and 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dfs</strong> (<em>pyspark.sql.dataframe.DataFrame</em>) – SparkDF with probabilities predictions.</p></li>
<li><p><strong>col_id</strong> (<em>str</em>) – Column name with id value, to count the values for each decile.</p></li>
<li><p><strong>col_target</strong> (<em>str</em>) – Column name with the ground truth. Must be from a binary classifier with values 1 and 0.</p></li>
<li><p><strong>col_probability</strong> (<em>str</em>) – Column name with the probability estimated from the model.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – If unique values from col_target column are not 0 and 1.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl>
<dt>SparkDF with the columns:</dt><dd><ul class="simple">
<li><p>percentile, min_prob, max_prob, count_id, events, non_events, cum_events,</p></li>
</ul>
<p>cum_non_events, precision_at_percentile, recall_at_percentile, event_rate,
nonevent_rate, cum_eventrate, cum_noneventrate, ks.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>pyspark.sql.dataframe.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.eval.estimate_individual_shapley_values">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.eval.</span></span><span class="sig-name descname"><span class="pre">estimate_individual_shapley_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spark</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.session.SparkSession</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">df</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id_col</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">column_of_interest</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">problem_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">row_of_interest</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">pyspark.sql.types.Row</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_col</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'features'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_shap_values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pyspark.sql.dataframe.DataFrame</span></span></span><a class="headerlink" href="#pyspark_ds_toolbox.ml.eval.estimate_individual_shapley_values" title="Permalink to this definition"></a></dt>
<dd><p>Function to estimate the shap values (explain prediction) for a row of interest.</p>
<p>This function is based on the algorithm described here:
<a class="reference external" href="https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-the-shapley-value">https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-the-shapley-value</a>
and the implementation presented here:
<a class="reference external" href="https://medium.com/mlearning-ai/machine-learning-interpretability-shapley-values-with-pyspark-16ffd87227e3">https://medium.com/mlearning-ai/machine-learning-interpretability-shapley-values-with-pyspark-16ffd87227e3</a></p>
<p>[to-do]
check: <a class="reference external" href="https://github.com/manuel-calzolari/shapicant">https://github.com/manuel-calzolari/shapicant</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>spark</strong> (<em>pyspark.sql.session.SparkSession</em>) – A Spark DF</p></li>
<li><p><strong>df</strong> (<em>pyspark.sql.dataframe.DataFrame</em>) – The result of applying a model.transform(df).
This df MUST have either a column with the prediction values (regression) or a column with the probabilities (classification).</p></li>
<li><p><strong>id_col</strong> (<em>str</em>) – Column name of the id column.</p></li>
<li><p><strong>model</strong> (<em>[</em><em>type</em><em>]</em>) – A trained spark ml model. #to-do check compatible types.</p></li>
<li><p><strong>column_of_interest</strong> (<em>str</em>) – Column name with the prediction values (regression) or the probability.
This is the column that the shap values refer to.</p></li>
<li><p><strong>problem_type</strong> (<em>str</em>) – Must be one one ‘classification’ or ‘regression’. See Raises section.</p></li>
<li><p><strong>row_of_interest</strong> (<em>pyspark.sql.types.Row</em>) – A row from the dataframe passed as df.</p></li>
<li><p><strong>feature_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – List with the features names.</p></li>
<li><p><strong>features_col</strong> (<em>str</em><em>, </em><em>optional</em>) – Column name of the features vector. Defaults to ‘features’.</p></li>
<li><p><strong>print_shap_values</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True will print the values as they are computed. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – if df.schema[id_col].dataType not in [T.FloatType(), T.LongType(), T.IntegerType()]==True</p></li>
<li><p><strong>ValueError</strong> – if not set(feature_names).issubset(df.columns)==True</p></li>
<li><p><strong>ValueError</strong> – problem_type not in [‘classification’, ‘regression’]</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>A sparkDF with the follwing columns</dt><dd><ul class="simple">
<li><p>id_col: The value from the column passed as id_col;</p></li>
<li><p>feature: The name of each feature from features_names;</p></li>
<li><p>shap: The shap value of the feature.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>[pyspark.sql.dataframe.DataFrame]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pyspark_ds_toolbox.ml.eval.get_p1">
<span class="sig-prename descclassname"><span class="pre">pyspark_ds_toolbox.ml.eval.</span></span><span class="sig-name descname"><span class="pre">get_p1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pyspark_ds_toolbox.ml.eval.get_p1" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-pyspark_ds_toolbox.ml">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pyspark_ds_toolbox.ml" title="Permalink to this headline"></a></h2>
<p>Machine Learning toolbox.</p>
<p>Subpackage dedicated to Machine Learning helpers.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="pyspark_ds_toolbox.causal_inference.html" class="btn btn-neutral float-left" title="pyspark_ds_toolbox.causal_inference package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Vinicius M de Sousa.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>