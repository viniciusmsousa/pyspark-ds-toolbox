{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Shap Values\n",
    "\n",
    "This notebook presentd the usage of the `estimate_individual_shapley_values()` function. It is based on the algorithm described in [interpretable-ml-book](https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-the-shapley-value) and the implementation presented [here](https://medium.com/mlearning-ai/machine-learning-interpretability-shapley-values-with-pyspark-16ffd87227e3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_ds_toolbox.ml.data_prep import get_features_vector\n",
    "from pyspark_ds_toolbox.ml.eval import get_p1, estimate_individual_shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/06 11:05:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                .appName('Ml-Pipes') \\\n",
    "                .master('local[1]') \\\n",
    "                .config('spark.executor.memory', '3G') \\\n",
    "                .config('spark.driver.memory', '3G') \\\n",
    "                .config('spark.memory.offHeap.enabled', 'true') \\\n",
    "                .config('spark.memory.offHeap.size', '3G') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "df = read_data('nsw_mixtape.dta')\n",
    "df = pd.concat((df, read_data('cps_mixtape.dta')))\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "df = spark.createDataFrame(df.drop(columns=['data_id']))\\\n",
    "    .withColumn('age2', F.col('age')**2)\\\n",
    "    .withColumn('age3', F.col('age')**3)\\\n",
    "    .withColumn('educ2', F.col('educ')**2)\\\n",
    "    .withColumn('educ_re74', F.col('educ')*F.col('re74'))\\\n",
    "    .withColumn('u74', F.when(F.col('re74')==0, 1).otherwise(0))\\\n",
    "    .withColumn('u75', F.when(F.col('re75')==0, 1).otherwise(0))\n",
    "\n",
    "features=['age', 'age2', 'age3', 'educ', 'educ2', 'marr', 'nodegree', 'black', 'hisp', 're74', 're75', 'u74', 'u75', 'educ_re74']\n",
    "df_assembled = get_features_vector(df=df, num_features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "train, test = df_assembled.randomSplit([train_size, (1-train_size)], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using in a Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Regression\n",
    "model_regressor = GBTRegressor(labelCol='re78')\n",
    "p_regression = Pipeline(stages=[model_regressor]).fit(train)\n",
    "sdf_prediction_regression = p_regression.transform(test)\n",
    "\n",
    "row_of_interest_reg = sdf_prediction_regression.orderBy(F.col('prediction').desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------------------+\n",
      "|index|feature|               shap|\n",
      "+-----+-------+-------------------+\n",
      "| 6197|    age|-7356.5805590092805|\n",
      "| 6197|   age2| 18.757125808299836|\n",
      "| 6197|   age3| 11.650084636037183|\n",
      "| 6197|   educ|  3990.985778910689|\n",
      "| 6197|  educ2| -33.71631236170338|\n",
      "+-----+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_shap_regression = estimate_individual_shapley_values(\n",
    "    spark=spark,\n",
    "    df = sdf_prediction_regression,\n",
    "    id_col='index',\n",
    "    model = p_regression,\n",
    "    column_of_interest='prediction',\n",
    "    problem_type='regression',\n",
    "    row_of_interest = row_of_interest_reg,\n",
    "    feature_names = features,\n",
    "    features_col='features',\n",
    "    print_shap_values=False\n",
    ")\n",
    "\n",
    "sdf_shap_regression.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated re78 from shap values decomposition:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24747.969288207067\n",
      "Observed re78:\n",
      "25564.669921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Estimated re78 from shap values decomposition:')\n",
    "v = sdf_prediction_regression.select('re78').toPandas().re78.mean() + sdf_shap_regression.select(F.sum('shap')).collect()[0][0]\n",
    "print(v)\n",
    "\n",
    "print('Observed re78:')\n",
    "v = row_of_interest_reg['re78']\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using in a Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Regression\n",
    "model_classifier = GBTClassifier(labelCol='treat')\n",
    "p_classification = Pipeline(stages=[model_classifier]).fit(train)\n",
    "\n",
    "sdf_prediction_classification = p_classification.transform(test)\\\n",
    "    .withColumn('p1', get_p1(F.col('probability')))\n",
    "\n",
    "row_of_interest_clas = sdf_prediction_classification.orderBy(F.col('p1').desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+\n",
      "|index|feature|                shap|\n",
      "+-----+-------+--------------------+\n",
      "|13922|    age| -27.899380519168098|\n",
      "|13922|   age2| -0.1111173935016898|\n",
      "|13922|   age3|0.021388909934701925|\n",
      "|13922|   educ|  4.1131150480755405|\n",
      "|13922|  educ2|5.151388818447742E-4|\n",
      "+-----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_shap_classification = estimate_individual_shapley_values(\n",
    "    spark=spark,\n",
    "    df = sdf_prediction_classification,\n",
    "    id_col='index',\n",
    "    model = p_classification,\n",
    "    column_of_interest='p1',\n",
    "    problem_type='classification',\n",
    "    row_of_interest = row_of_interest_clas,\n",
    "    feature_names = features,\n",
    "    features_col='features',\n",
    "    print_shap_values=False\n",
    ")\n",
    "\n",
    "sdf_shap_classification.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated treat prob from shap values decomposition:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6212793648137955\n",
      "Estimated treat prob directly from model:\n",
      "0.6212793588638306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Estimated treat prob from shap values decomposition:')\n",
    "print(sdf_prediction_classification.select('p1').toPandas().p1.mean() + sdf_shap_classification.select(F.sum('shap')).collect()[0][0])\n",
    "\n",
    "\n",
    "print('Estimated treat prob directly from model:')\n",
    "v = row_of_interest_clas['p1']\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "604c540002d7c1a602a115001e40004a700e7e1b29ae4331249882fda5e70a0c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pyspark-ds-toolbox-Fn-Rjt-3-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
