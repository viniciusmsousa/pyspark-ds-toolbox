{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Shap Values\n",
    "\n",
    "This notebook presentd the usage of the `estimate_individual_shapley_values()` function. It is based on the algorithm described in [interpretable-ml-book](https://christophm.github.io/interpretable-ml-book/shapley.html#estimating-the-shapley-value) and the implementation presented [here](https://medium.com/mlearning-ai/machine-learning-interpretability-shapley-values-with-pyspark-16ffd87227e3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark_ds_toolbox.ml.feature_importance.shap_values import estimate_shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lendo o dataset base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>treat</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>marr</th>\n",
       "      <th>nodegree</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.045898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.894043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.449219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.145996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.789886</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                data_id  treat   age  educ  black  hisp  marr  nodegree  re74  \\\n",
       "0  Dehejia-Wahba Sample      1  37.0  11.0    1.0   0.0   1.0       1.0   0.0   \n",
       "1  Dehejia-Wahba Sample      1  22.0   9.0    0.0   1.0   0.0       1.0   0.0   \n",
       "2  Dehejia-Wahba Sample      1  30.0  12.0    1.0   0.0   0.0       0.0   0.0   \n",
       "3  Dehejia-Wahba Sample      1  27.0  11.0    1.0   0.0   0.0       1.0   0.0   \n",
       "4  Dehejia-Wahba Sample      1  33.0   8.0    1.0   0.0   0.0       1.0   0.0   \n",
       "\n",
       "   re75          re78  id  \n",
       "0   0.0   9930.045898   0  \n",
       "1   0.0   3595.894043   1  \n",
       "2   0.0  24909.449219   2  \n",
       "3   0.0   7506.145996   3  \n",
       "4   0.0    289.789886   4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "df = read_data('nsw_mixtape.dta')\n",
    "df = pd.concat((df, read_data('cps_mixtape.dta')))\n",
    "df['treat'] = df['treat'].astype(int)\n",
    "#df.reset_index(level=0, inplace=True)\n",
    "#df.rename(columns={'index':'id'}, inplace=True)\n",
    "df['id'] = np.arange(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/14 17:01:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                .appName('Spark-Toolbox') \\\n",
    "                .master('local[1]') \\\n",
    "                .config('spark.executor.memory', '3G') \\\n",
    "                .config('spark.driver.memory', '3G') \\\n",
    "                .config('spark.memory.offHeap.enabled', 'true') \\\n",
    "                .config('spark.memory.offHeap.size', '3G') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+--------+---+\n",
      "|             data_id|treat| age|educ|black|hisp|marr|nodegree|re74|re75|    re78| id|\n",
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+--------+---+\n",
      "|Dehejia-Wahba Sample|    1|37.0|11.0|  1.0| 0.0| 1.0|     1.0| 0.0| 0.0|9930.046|  0|\n",
      "|Dehejia-Wahba Sample|    1|22.0| 9.0|  0.0| 1.0| 0.0|     1.0| 0.0| 0.0|3595.894|  1|\n",
      "|Dehejia-Wahba Sample|    1|30.0|12.0|  1.0| 0.0| 0.0|     0.0| 0.0| 0.0|24909.45|  2|\n",
      "+--------------------+-----+----+----+-----+----+----+--------+----+----+--------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.createDataFrame(df)\n",
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = estimate_shap_values(\n",
    "    sdf=sdf,\n",
    "    id_col='id',\n",
    "    target_col='re78',\n",
    "    cat_features = ['data_id'],\n",
    "    sort_metric='rmse',\n",
    "    problem_type='regression',\n",
    "    subset_size = 1000,\n",
    "    max_mem_size = '2G',\n",
    "    max_models=8,\n",
    "    max_runtime_secs=15,\n",
    "    nfolds=5,\n",
    "    seed=90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap_values.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_classification = estimate_shap_values(\n",
    "    sdf=sdf,\n",
    "    id_col='id',\n",
    "    target_col='treat',\n",
    "    cat_features = ['data_id'],\n",
    "    sort_metric='aucpr',\n",
    "    problem_type='classification',\n",
    "    subset_size = 1000,\n",
    "    max_mem_size = '2G',\n",
    "    max_models=8,\n",
    "    max_runtime_secs=15,\n",
    "    nfolds=5,\n",
    "    seed=90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap_values_classification.show(20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "604c540002d7c1a602a115001e40004a700e7e1b29ae4331249882fda5e70a0c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pyspark-ds-toolbox-Fn-Rjt-3-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
