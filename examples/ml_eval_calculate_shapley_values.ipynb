{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vini/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://github.com/manuel-calzolari/shapicant\n",
    "import pandas as pd\n",
    "# from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "# from pyspark.sql.types import FloatType, StructField, StructType, StringType\n",
    "# from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "import pyspark.ml.feature as FF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import GBTRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_ds_toolbox.ml.data_prep import get_features_vector\n",
    "from pyspark_ds_toolbox.ml.eval import get_p1, estimate_individual_shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/04 14:37:57 WARN Utils: Your hostname, matrix.local resolves to a loopback address: 127.0.0.1; using 172.20.10.3 instead (on interface en0)\n",
      "21/12/04 14:37:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/vini/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/12/04 14:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                .appName('Ml-Pipes') \\\n",
    "                .master('local[1]') \\\n",
    "                .config('spark.executor.memory', '3G') \\\n",
    "                .config('spark.driver.memory', '3G') \\\n",
    "                .config('spark.memory.offHeap.enabled', 'true') \\\n",
    "                .config('spark.memory.offHeap.size', '3G') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "df = read_data('nsw_mixtape.dta')\n",
    "df = pd.concat((df, read_data('cps_mixtape.dta')))\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "df = spark.createDataFrame(df.drop(columns=['data_id']))\\\n",
    "    .withColumn('age2', F.col('age')**2)\\\n",
    "    .withColumn('age3', F.col('age')**3)\\\n",
    "    .withColumn('educ2', F.col('educ')**2)\\\n",
    "    .withColumn('educ_re74', F.col('educ')*F.col('re74'))\\\n",
    "    .withColumn('u74', F.when(F.col('re74')==0, 1).otherwise(0))\\\n",
    "    .withColumn('u75', F.when(F.col('re75')==0, 1).otherwise(0))\n",
    "\n",
    "features=['age', 'age2', 'age3', 'educ', 'educ2', 'marr', 'nodegree', 'black', 'hisp', 're74', 're75', 'u74', 'u75', 'educ_re74']\n",
    "df_assembled = get_features_vector(df=df, num_features=features)\n",
    "\n",
    "# assembler = FF.VectorAssembler(inputCols=features, outputCol='features')\n",
    "# pipeline = Pipeline(stages = [assembler])\n",
    "# df_assembled = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "train, test = df_assembled.randomSplit([train_size, (1-train_size)], seed=12345)\n",
    "\n",
    "row_of_interest = df_assembled.filter(F.col('index')==3).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using in a Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "model_regressor = GBTRegressor(labelCol='re78')\n",
    "p_regression = Pipeline(stages=[model_regressor]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------------------+\n",
      "|index|feature|              shap|\n",
      "+-----+-------+------------------+\n",
      "|    3|    age| 935.1710310392384|\n",
      "|    3|   age2|131.16309833128466|\n",
      "|    3|   age3|122.37308194603968|\n",
      "|    3|   educ| -450.768881698199|\n",
      "|    3|  educ2|114.58859573810376|\n",
      "+-----+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_shap_regression = estimate_individual_shapley_values(\n",
    "    spark=spark,\n",
    "    df = df_assembled,\n",
    "    id_col='index',\n",
    "    model = p_regression,\n",
    "    problem_type='regression',\n",
    "    row_of_interest = row_of_interest,\n",
    "    feature_names = features,\n",
    "    features_col='features',\n",
    "    print_shap_values=False\n",
    ")\n",
    "\n",
    "sdf_shap_regression.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated re78 from shap values decomposition:\n",
      "10959.500462485266\n",
      "Observed re78:\n",
      "7506.14599609375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Estimated re78 from shap values decomposition:')\n",
    "print(df_assembled.select('re78').toPandas().re78.mean() + sdf_shap_regression.select(F.sum('shap')).collect()[0][0])\n",
    "\n",
    "print('Observed re78:')\n",
    "v = df_assembled.filter(F.col('index')==3).select('re78').collect()[0][0]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using in a Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "model_classifier = GBTClassifier(labelCol='treat')\n",
    "p_classification = Pipeline(stages=[model_classifier]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+\n",
      "|index|feature|                shap|\n",
      "+-----+-------+--------------------+\n",
      "|    3|    age|-0.00763664486855...|\n",
      "|    3|   age2|-0.00403245308362...|\n",
      "|    3|   age3|-0.00430382868062...|\n",
      "|    3|   educ|0.006123442326710661|\n",
      "|    3|  educ2|-0.00407094088591659|\n",
      "+-----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_shap_classification = estimate_individual_shapley_values(\n",
    "    spark=spark,\n",
    "    df = df_assembled,\n",
    "    id_col='index',\n",
    "    model = p_classification,\n",
    "    problem_type='classification',\n",
    "    row_of_interest = row_of_interest,\n",
    "    feature_names = features,\n",
    "    features_col='features',\n",
    "    print_shap_values=False\n",
    ")\n",
    "\n",
    "sdf_shap_classification.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated treat prob from shap values decomposition:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28614638016471244"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('Estimated treat prob from shap values decomposition:')\n",
    "# print(df_assembled.select('p1').toPandas().p1.mean() + sdf_shap_classification.select(F.sum('shap')).collect()[0][0])\n",
    "sdf_shap_classification.select(F.sum('shap')).collect()[0][0]\n",
    "\n",
    "# print('Observed re78:')\n",
    "# v = df_assembled.filter(F.col('index')==3).select('re78').collect()[0][0]\n",
    "# print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`probability`' given input columns: [age, age2, age3, black, educ, educ2, educ_re74, features, hisp, index, marr, nodegree, re74, re75, re78, treat, u74, u75];\n'Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138, <lambda>('probability) AS p1#15227]\n+- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138]\n   +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, num#118, UDF(struct(num, num#118)) AS features#138]\n      +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, UDF(struct(age, age#2, age2, age2#22, age3, age3#35, educ, educ#3, educ2, educ2#49, marr, marr#6, nodegree, nodegree#7, black, black#4, hisp, hisp#5, re74, re74#8, re75, re75#9, u74_double_VectorAssembler_870952b30f34, cast(u74#80 as double), ... 4 more fields)) AS num#118]\n         +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, CASE WHEN (re75#9 = cast(0 as double)) THEN 1 ELSE 0 END AS u75#97]\n            +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, CASE WHEN (re74#8 = cast(0 as double)) THEN 1 ELSE 0 END AS u74#80]\n               +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, (educ#3 * re74#8) AS educ_re74#64]\n                  +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, POWER(educ#3, cast(2 as double)) AS educ2#49]\n                     +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, POWER(age#2, cast(3 as double)) AS age3#35]\n                        +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, POWER(age#2, cast(2 as double)) AS age2#22]\n                           +- LogicalRDD [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/frm4xmyd25bdq89lxc8bq31r0000gn/T/ipykernel_1072/4215091407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_assembled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_p1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \"\"\"\n\u001b[1;32m   2454\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`probability`' given input columns: [age, age2, age3, black, educ, educ2, educ_re74, features, hisp, index, marr, nodegree, re74, re75, re78, treat, u74, u75];\n'Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138, <lambda>('probability) AS p1#15227]\n+- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138]\n   +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, num#118, UDF(struct(num, num#118)) AS features#138]\n      +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, UDF(struct(age, age#2, age2, age2#22, age3, age3#35, educ, educ#3, educ2, educ2#49, marr, marr#6, nodegree, nodegree#7, black, black#4, hisp, hisp#5, re74, re74#8, re75, re75#9, u74_double_VectorAssembler_870952b30f34, cast(u74#80 as double), ... 4 more fields)) AS num#118]\n         +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, CASE WHEN (re75#9 = cast(0 as double)) THEN 1 ELSE 0 END AS u75#97]\n            +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, CASE WHEN (re74#8 = cast(0 as double)) THEN 1 ELSE 0 END AS u74#80]\n               +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, (educ#3 * re74#8) AS educ_re74#64]\n                  +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, POWER(educ#3, cast(2 as double)) AS educ2#49]\n                     +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, POWER(age#2, cast(3 as double)) AS age3#35]\n                        +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, POWER(age#2, cast(2 as double)) AS age2#22]\n                           +- LogicalRDD [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10], false\n"
     ]
    }
   ],
   "source": [
    "df_predicted = df_assembled.withColumn('p1', get_p1(F.col('probability')))\n",
    "\n",
    "print(df_predicted.select('p1').toPandas().p1.mean() + a.select(F.sum('shap')).collect()[0][0])\n",
    "\n",
    "v = df_predicted.filter(F.col('index')==3).select('p1').collect()[0][0]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`probability`' given input columns: [age, age2, age3, black, educ, educ2, educ_re74, features, hisp, index, marr, nodegree, re74, re75, re78, treat, u74, u75];\n'Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138, <lambda>('probability) AS p1#15227]\n+- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138]\n   +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, num#118, UDF(struct(num, num#118)) AS features#138]\n      +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, UDF(struct(age, age#2, age2, age2#22, age3, age3#35, educ, educ#3, educ2, educ2#49, marr, marr#6, nodegree, nodegree#7, black, black#4, hisp, hisp#5, re74, re74#8, re75, re75#9, u74_double_VectorAssembler_870952b30f34, cast(u74#80 as double), ... 4 more fields)) AS num#118]\n         +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, CASE WHEN (re75#9 = cast(0 as double)) THEN 1 ELSE 0 END AS u75#97]\n            +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, CASE WHEN (re74#8 = cast(0 as double)) THEN 1 ELSE 0 END AS u74#80]\n               +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, (educ#3 * re74#8) AS educ_re74#64]\n                  +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, POWER(educ#3, cast(2 as double)) AS educ2#49]\n                     +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, POWER(age#2, cast(3 as double)) AS age3#35]\n                        +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, POWER(age#2, cast(2 as double)) AS age2#22]\n                           +- LogicalRDD [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[0;32m/var/folders/f5/frm4xmyd25bdq89lxc8bq31r0000gn/T/ipykernel_1072/4215091407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_assembled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_p1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'probability'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n",
      "\u001b[1;32m   2453\u001b[0m         \"\"\"\n",
      "\u001b[1;32m   2454\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 2455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   2457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n",
      "\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n",
      "\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m~/Dev-Files/Poetry/virtualenvs/pyspark-ds-toolbox-H0pw_EKR-py3.8/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n",
      "\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`probability`' given input columns: [age, age2, age3, black, educ, educ2, educ_re74, features, hisp, index, marr, nodegree, re74, re75, re78, treat, u74, u75];\n",
      "'Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138, <lambda>('probability) AS p1#15227]\n",
      "+- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, features#138]\n",
      "   +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, num#118, UDF(struct(num, num#118)) AS features#138]\n",
      "      +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, u75#97, UDF(struct(age, age#2, age2, age2#22, age3, age3#35, educ, educ#3, educ2, educ2#49, marr, marr#6, nodegree, nodegree#7, black, black#4, hisp, hisp#5, re74, re74#8, re75, re75#9, u74_double_VectorAssembler_870952b30f34, cast(u74#80 as double), ... 4 more fields)) AS num#118]\n",
      "         +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, u74#80, CASE WHEN (re75#9 = cast(0 as double)) THEN 1 ELSE 0 END AS u75#97]\n",
      "            +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, educ_re74#64, CASE WHEN (re74#8 = cast(0 as double)) THEN 1 ELSE 0 END AS u74#80]\n",
      "               +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, educ2#49, (educ#3 * re74#8) AS educ_re74#64]\n",
      "                  +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, age3#35, POWER(educ#3, cast(2 as double)) AS educ2#49]\n",
      "                     +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, age2#22, POWER(age#2, cast(3 as double)) AS age3#35]\n",
      "                        +- Project [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10, POWER(age#2, cast(2 as double)) AS age2#22]\n",
      "                           +- LogicalRDD [index#0L, treat#1, age#2, educ#3, black#4, hisp#5, marr#6, nodegree#7, re74#8, re75#9, re78#10], false\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Classification\n",
    "model_classifier = GBTClassifier(labelCol='treat')\n",
    "p_classifier = Pipeline(stages=[model_classifier]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18014.104953822396"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted.select('re78').toPandas().re78.mean() + a.select(F.sum('shap')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04829068469926582\n",
      "0.04364077374339104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df_predicted.select('probability').toPandas().probability.mean() + a.select(F.sum('shap')).collect()[0][0])\n",
    "\n",
    "print(f'{v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052278824448785434\n",
      "0.043646443635225296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(df_predicted.select('probability').toPandas().probability.mean() + a.select(F.sum('shap')).collect()[0][0])\n",
    "\n",
    "print(f'{v}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "604c540002d7c1a602a115001e40004a700e7e1b29ae4331249882fda5e70a0c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pyspark-ds-toolbox-Fn-Rjt-3-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
