{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Value as Feature Selection for Binary Classification Problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.get_option(\"display.max_columns\")\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark_ds_toolbox.ml.feature_selection import feature_selection_with_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/30 00:21:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                .appName('Spark-Toolbox') \\\n",
    "                .master('local[1]') \\\n",
    "                .config('spark.executor.memory', '3G') \\\n",
    "                .config('spark.driver.memory', '3G') \\\n",
    "                .config('spark.memory.offHeap.enabled', 'true') \\\n",
    "                .config('spark.memory.offHeap.size', '3G') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lendo o dataset base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+--------------------+-----+--------+-----+\n",
      "|index| age|educ|             data_id|etnia|dumb_cat|treat|\n",
      "+-----+----+----+--------------------+-----+--------+-----+\n",
      "|    0|37.0|11.0|Dehejia-Wahba Sample|black|       b|    1|\n",
      "|    3|48.0| 6.0|                CPS1| marr|       b|    0|\n",
      "|    7|18.0|11.0|                CPS1|other|       b|    0|\n",
      "|   10|19.0| 9.0|Dehejia-Wahba Sample|black|       b|    1|\n",
      "|   12|18.0| 8.0|Dehejia-Wahba Sample|black|       a|    1|\n",
      "+-----+----+----+--------------------+-----+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def read_data(file): \n",
    "    return pd.read_stata(\"https://raw.github.com/scunning1975/mixtape/master/\" + file)\n",
    "\n",
    "df = read_data('nsw_mixtape.dta')\n",
    "df = pd.concat((df, read_data('cps_mixtape.dta')))\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "df = spark.createDataFrame(df)\\\n",
    "    .withColumn('etnia', F.expr('case when black=1 then \"black\" when hisp=1 then \"hisp\" when marr=1 then \"marr\" else \"other\" end'))\\\n",
    "    .withColumn('treat', F.col('treat').cast('int'))\\\n",
    "    .withColumn('dumb_cat', F.expr('case when index > 10 then \"a\" else \"b\" end'))\\\n",
    "    .select('index', 'age', 'educ', 'data_id', 'etnia','dumb_cat', 'treat')\n",
    "\n",
    "\n",
    "\n",
    "dfs_train, dfs_test = df.randomSplit([0.8, 0.2], seed=4)\n",
    "dfs_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Encoding 1\n",
    "\n",
    "Supose we want to predict the `treat` column with all the other columns, except `index`. We will call the `feature_selection_with_iv()` function the select only the features with a information value greater or equal then 0.3. We will also encode the categorical features with their WOE, instead of doing a one hot encoding.\n",
    "\n",
    "By definition we know that column `dumb_cat` should be be taken into account, since it adds no information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = feature_selection_with_iv(\n",
    "    dfs=dfs_train,\n",
    "    col_target='treat',\n",
    "    cat_features=['data_id', 'etnia', 'dumb_cat'],\n",
    "    num_features=['age', 'educ'],\n",
    "    floor_iv=0.3,\n",
    "    bucket_fraction=0.1,\n",
    "    categorical_as_woe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calss returns a dictionary with the following keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dfs_woe', 'dfs_iv', 'stages_features_vector'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`result['dfs_woe']` has all feature values weight of evidence and information value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+--------------------+\n",
      "|   feature|feature_value|                 woe|                  iv|\n",
      "+----------+-------------+--------------------+--------------------+\n",
      "|age_bucket|          0.0| -0.5972201927175608| 0.03755893994515182|\n",
      "|age_bucket|          5.0|  0.4674214381624044|0.019477216762649557|\n",
      "|age_bucket|          1.0|-0.42042489967372465|0.020182294438309992|\n",
      "|age_bucket|          6.0|  0.9472248535629343| 0.05228097899890407|\n",
      "|age_bucket|          9.0|                 0.0|                 0.0|\n",
      "+----------+-------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result['dfs_woe'].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`result['dfs_iv']` has each feature information value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|    feature|                iv|\n",
      "+-----------+------------------+\n",
      "|    data_id| 4.081508165850559|\n",
      "|      etnia| 4.076126036555841|\n",
      "|educ_bucket|1.0052276924505816|\n",
      "| age_bucket|0.4417967451554041|\n",
      "|   dumb_cat|0.2845468150802483|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result['df_iv'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally result['stages_features_vector'] has a list os transformers and estimators to create a features vector column with the selected variables and categorical encoding bases on `floor_iv` and `categorical_as_woe` params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WeightOfEvidenceComputer_8752fb7b720b,\n",
       " VectorAssembler_b64f31fe701a,\n",
       " VectorAssembler_c70d931586a2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['stages_features_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>data_id</th>\n",
       "      <th>etnia</th>\n",
       "      <th>dumb_cat</th>\n",
       "      <th>treat</th>\n",
       "      <th>data_id_woe</th>\n",
       "      <th>etnia_woe</th>\n",
       "      <th>num</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>black</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.090093</td>\n",
       "      <td>-2.343053</td>\n",
       "      <td>[37.0, 11.0, -4.090093113364742, -2.3430534792...</td>\n",
       "      <td>[37.0, 11.0, -4.090093113364742, -2.3430534792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>CPS1</td>\n",
       "      <td>marr</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.234625</td>\n",
       "      <td>[48.0, 6.0, 0.0, 3.234624562237972]</td>\n",
       "      <td>[48.0, 6.0, 0.0, 3.234624562237972]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CPS1</td>\n",
       "      <td>other</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.202206</td>\n",
       "      <td>[18.0, 11.0, 0.0, 1.2022061808577313]</td>\n",
       "      <td>[18.0, 11.0, 0.0, 1.2022061808577313]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>black</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.090093</td>\n",
       "      <td>-2.343053</td>\n",
       "      <td>[19.0, 9.0, -4.090093113364742, -2.34305347926...</td>\n",
       "      <td>[19.0, 9.0, -4.090093113364742, -2.34305347926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>black</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.090093</td>\n",
       "      <td>-2.343053</td>\n",
       "      <td>[18.0, 8.0, -4.090093113364742, -2.34305347926...</td>\n",
       "      <td>[18.0, 8.0, -4.090093113364742, -2.34305347926...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   age  educ               data_id  etnia dumb_cat  treat  \\\n",
       "0      0  37.0  11.0  Dehejia-Wahba Sample  black        b      1   \n",
       "1      3  48.0   6.0                  CPS1   marr        b      0   \n",
       "2      7  18.0  11.0                  CPS1  other        b      0   \n",
       "3     10  19.0   9.0  Dehejia-Wahba Sample  black        b      1   \n",
       "4     12  18.0   8.0  Dehejia-Wahba Sample  black        a      1   \n",
       "\n",
       "   data_id_woe  etnia_woe                                                num  \\\n",
       "0    -4.090093  -2.343053  [37.0, 11.0, -4.090093113364742, -2.3430534792...   \n",
       "1     0.000000   3.234625                [48.0, 6.0, 0.0, 3.234624562237972]   \n",
       "2     0.000000   1.202206              [18.0, 11.0, 0.0, 1.2022061808577313]   \n",
       "3    -4.090093  -2.343053  [19.0, 9.0, -4.090093113364742, -2.34305347926...   \n",
       "4    -4.090093  -2.343053  [18.0, 8.0, -4.090093113364742, -2.34305347926...   \n",
       "\n",
       "                                            features  \n",
       "0  [37.0, 11.0, -4.090093113364742, -2.3430534792...  \n",
       "1                [48.0, 6.0, 0.0, 3.234624562237972]  \n",
       "2              [18.0, 11.0, 0.0, 1.2022061808577313]  \n",
       "3  [19.0, 9.0, -4.090093113364742, -2.34305347926...  \n",
       "4  [18.0, 8.0, -4.090093113364742, -2.34305347926...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=result['stages_features_vector'])\n",
    "\n",
    "pipeline_fitted = pipeline.fit(dfs_train)\n",
    "\n",
    "pipeline_fitted.transform(dfs_test).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we only have WOE column for `data_id` and `etnia`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Encoding 2\n",
    "\n",
    "If we just change the param `categorical_as_woe` we will have the same result but with the selected categorical features being encoded with one hot encoding, which is the default behavior of `pyspark_ds_toolbox.ml.data_prep.features_vector.get_features_vector()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = feature_selection_with_iv(\n",
    "    dfs=dfs_train,\n",
    "    col_target='treat',\n",
    "    cat_features=['data_id', 'etnia', 'dumb_cat'],\n",
    "    num_features=['age', 'educ'],\n",
    "    floor_iv=0.3,\n",
    "    bucket_fraction=0.1,\n",
    "    categorical_as_woe=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_302f336d0c3c,\n",
       " StringIndexer_ea57a18d6a3a,\n",
       " OneHotEncoder_f93f5ce803c2,\n",
       " OneHotEncoder_de4141bdbc59,\n",
       " VectorAssembler_5b681f30defe,\n",
       " VectorAssembler_c87edb123b6f,\n",
       " VectorAssembler_6383377847e0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['stages_features_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>data_id</th>\n",
       "      <th>etnia</th>\n",
       "      <th>dumb_cat</th>\n",
       "      <th>treat</th>\n",
       "      <th>data_id_indexed</th>\n",
       "      <th>etnia_indexed</th>\n",
       "      <th>data_id_indexed_encoded</th>\n",
       "      <th>etnia_indexed_encoded</th>\n",
       "      <th>cat</th>\n",
       "      <th>num</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>black</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0)</td>\n",
       "      <td>[37.0, 11.0]</td>\n",
       "      <td>[37.0, 11.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>CPS1</td>\n",
       "      <td>marr</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[48.0, 6.0]</td>\n",
       "      <td>[48.0, 6.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CPS1</td>\n",
       "      <td>other</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0)</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[18.0, 11.0]</td>\n",
       "      <td>[18.0, 11.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>black</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0)</td>\n",
       "      <td>[19.0, 9.0]</td>\n",
       "      <td>[19.0, 9.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Dehejia-Wahba Sample</td>\n",
       "      <td>black</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0)</td>\n",
       "      <td>[18.0, 8.0]</td>\n",
       "      <td>[18.0, 8.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   age  educ               data_id  etnia dumb_cat  treat  \\\n",
       "0      0  37.0  11.0  Dehejia-Wahba Sample  black        b      1   \n",
       "1      3  48.0   6.0                  CPS1   marr        b      0   \n",
       "2      7  18.0  11.0                  CPS1  other        b      0   \n",
       "3     10  19.0   9.0  Dehejia-Wahba Sample  black        b      1   \n",
       "4     12  18.0   8.0  Dehejia-Wahba Sample  black        a      1   \n",
       "\n",
       "   data_id_indexed  etnia_indexed data_id_indexed_encoded  \\\n",
       "0              1.0            2.0                   (0.0)   \n",
       "1              0.0            0.0                   (1.0)   \n",
       "2              0.0            1.0                   (1.0)   \n",
       "3              1.0            2.0                   (0.0)   \n",
       "4              1.0            2.0                   (0.0)   \n",
       "\n",
       "  etnia_indexed_encoded                   cat           num  \\\n",
       "0       (0.0, 0.0, 1.0)  (0.0, 0.0, 0.0, 1.0)  [37.0, 11.0]   \n",
       "1       (1.0, 0.0, 0.0)  [1.0, 1.0, 0.0, 0.0]   [48.0, 6.0]   \n",
       "2       (0.0, 1.0, 0.0)  [1.0, 0.0, 1.0, 0.0]  [18.0, 11.0]   \n",
       "3       (0.0, 0.0, 1.0)  (0.0, 0.0, 0.0, 1.0)   [19.0, 9.0]   \n",
       "4       (0.0, 0.0, 1.0)  (0.0, 0.0, 0.0, 1.0)   [18.0, 8.0]   \n",
       "\n",
       "                           features  \n",
       "0  [37.0, 11.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "1   [48.0, 6.0, 1.0, 1.0, 0.0, 0.0]  \n",
       "2  [18.0, 11.0, 1.0, 0.0, 1.0, 0.0]  \n",
       "3   [19.0, 9.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "4   [18.0, 8.0, 0.0, 0.0, 0.0, 1.0]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=result['stages_features_vector'])\n",
    "\n",
    "pipeline_fitted = pipeline.fit(dfs_train)\n",
    "\n",
    "pipeline_fitted.transform(dfs_test).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "604c540002d7c1a602a115001e40004a700e7e1b29ae4331249882fda5e70a0c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pyspark-ds-toolbox-Fn-Rjt-3-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
